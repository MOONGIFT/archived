---
layout: post
title: "日々のサイト運用に。Ruby製のリンクチェッカー「rawler」"
date: 2011-01-30T21:00:00+09:00
categories:
- ソフトウェア
- Web
- オープンソース
tags: 
- プラットフォーム - CUI
- プログラミング言語 - Ruby
- 技術 - クローラー
- ホスティング - github
- ライセンス - MIT License
permalink: /2011/01/20110130-2/
catch: https://images.moongift.jp/2011/01/ScreenShot2011-01-21-14.10.35_thumb.png
id: 24875
---
rawlerはRubyで作られたコンソールで動作するリンクチェッカー

  

rawlerはRuby製のオープンソース・ソフトウェア。Webサイトを運営していると、リンクが変更されたりドメインごと移転したりする。そうした作業の蓄積によって、次第にリンク切れが発生していく。だがこれまでのコンテンツ全てについてチェックするのは大変だ。

  

![](https://images.moongift.jp/2011/01/ScreenShot2011-01-21-14.10.22_thumb.png)  
**実行中**

  

そこで使われるのがリンクチェッカーだ。自動的にチェックしてくれる仕組みがあれば、毎日自動実行しておいても良いくらいだ。既存のサイトはもちろん、新規サイトでも事前にチェックできる。そのためのライブラリがrawlerだ。

  
<!--more-->  

rawlerはコンソールで使うソフトウェアで、rawlerコマンドの後にURLを与えるだけで利用できる。そうするとドメイン以下にあるリンクについて自動でチェックを開始する。今の所リダイレクトがあった場合は301ないし302と出力されるだけになっている。また、HTMLのみ対応している。

  

![](https://images.moongift.jp/2011/01/ScreenShot2011-01-21-14.10.35_thumb.png)  
**ヘルプ**

  

結果はURLとレスポンスコードが一覧になって表示されるようになっている。今後robots.txtへの対応やHTML出力が予定されている。Basic認証にも対応しているので、RESTfulなサービスならば認証があっても使えそうだ。単純な機能しかないが、ターミナルから使えるのは便利だ。

  
  
  

**MOONGIFTはこう見る**

  

今のところは機能がごく少ないようで、MOONGIFTで試した所エラーが出てしまった。また、Yahoo!で試した所リダイレクトばかりになってしまった。そのためあまりシステム化が進んでいるサイトでは使えないかも知れない。もっとシンプルなサイト構成なら問題ないだろう。

  

日々自動実行し、200/300系以外のコードがあればメールするようなシステムにすれば、リンク切れによる機会損失が防げるようになるのではないだろうか。

  

via [rawler: Crawl your website and find broken links with Ruby - The Changelog - Open Source moves fast. Keep up.](http://thechangelog.com/post/2833125978/rawler-crawl-your-website-and-find-broken-links-with-rub)

  

[oscardelben/rawler - GitHub](https://github.com/oscardelben/rawler)

