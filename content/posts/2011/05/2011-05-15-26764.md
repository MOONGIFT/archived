---
layout: post
title: "Safariで見ているページを含めてリンク先もまとめてAmazon S3へ保存「BrowserCrawler」"
date: 2011-05-15T12:00:00+09:00
categories:
- ソフトウェア
- オープンソース
tags: 
- ライセンス - Apache License 2.0
- ホスティング - github
- ブラウザ - Safari
- 機能拡張 - Safari機能拡張
- プラットフォーム - GUI
- 技術 - HTML
- 技術 - クローラ
permalink: /2011/05/20110515-2/
catch: https://images.moongift.jp/2011/05/ScreenShot2011-05-07-13.28.45_thumb.png
id: 26764
---
BrowserCrawlerはSafari機能拡張として動作するクローラ。データはAmazon S3に保存される。

  

BrowserCrawlerはSafari向けのオープンソース・ソフトウェア。Webブラウジングをしていて、サイトを保存しておきたいと思うことがある。クリッピングサービスは幾つかあるが、有名なものとしてはEvernoteが挙げられるだろう。

  

![](https://images.moongift.jp/2011/05/ScreenShot2011-05-07-14.00.15_thumb.png)  
**クローリング中**

  

しかし今見ているページだけは保存できても、そこからのリンク先が保存できる訳ではない。そこでクローリング機能を備えたBrowserCrawlerを使ってみよう。

  
<!--more-->  

BrowserCrawlerはSafari機能拡張で、ボタン一つで現在表示されているページとその先のリンク先を含めたクローリングを行ってくれる。データはAmazon S3に保存する仕組みになっている。なお保存されるのはHTMLのみで、画像は保存されないようだ。

  

![](https://images.moongift.jp/2011/05/ScreenShot2011-05-07-13.28.45_thumb.png)  
**設定画面**

  

S3の指定したバケットの中に、ドメイン名のフォルダができ、さらにその中にパスに合わせてフォルダが作られてファイルが保存される。画像や動画を保存したいという用途には向かないが、テキストで全文検索したいという時には便利そうだ。リファレンスサイトやプロジェクトサイト全体を保存しておきたいという時に使えるだろう。

  
  
  

**MOONGIFTはこう見る**

  

自動的に保存されるのかと思ったが、そうではないようだ。BrowserCrawlerはクリッピング目的もあるが何よりも大事なのが既知の情報を保存しておいてくれるということだ。未知の情報はGoogleでも探せるが、知った情報を後で探すのというのは意外と時間がかかる場合が多い。

  

BrowserCrawlerはユーザ自身のCookieを使ってクローリングを行うので認証を伴うようなサイトでもクローリングできるのが特徴になる。覚えておきたい情報があればボタンをどんどん押していこう。

  

[spullara/browsercrawler - GitHub](https://github.com/spullara/browsercrawler)

